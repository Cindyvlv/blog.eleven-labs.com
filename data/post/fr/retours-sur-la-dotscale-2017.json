{"date":"2017-05-09T00:00:00.000Z","title":"Retours sur la dotScale 2017","excerpt":"Nous avons assisté à la 5ème édition de la dotScale (2017) qui se tenait cette année à Paris. Cette édition se déroulait dans le Théâtre de Paris et nous tenons à saluer les partenaires et volontaires pour l’organisation de cette conférence qui s’est très bien déroulée.","readingTime":"11mn","authors":["vcomposieux"],"categories":["architecture"],"content":"Nous avons assisté à la 5ème édition de la dotScale (2017) qui se tenait cette année à Paris. Cette édition se déroulait dans le Théâtre de Paris et nous tenons à saluer les partenaires et volontaires pour l’organisation de cette conférence qui s’est très bien déroulée.\n\n# Introduction\n\nBeaucoup de monde dans ce théâtre et beaucoup de stands sponsors/partenaires variés entre outils de monitoring, Google Cloud Platform, outils publicitaires ou de réservation en ligne.\n\nCôté conférences, beaucoup de contenu autour du scaling d'applications, de bases de données, mais aussi certaines très intéressantes sur des sujets annexes comme la gestion de crise en production sur de grosses infrastructures.\n\nSi vous n’avez pas pu y participer, pas de panique, nous vous avons préparé un retour sur les talks ayant eu lieu lors de cette édition :\n\n## Benjamin Hindman - Co-créateur d'Apache Mesos et Co-fondateur de Mesosphere\n\nBenjamin nous décrit dans ce talk le fonctionnement d'Apache Mesos et de ce que sa société Mesosphere peut mettre en place.\n\nIl faut avant tout connaitre l'utilité d'Apache Mesos : il s'agit d'un outil permettant de gérer les ressources d'un datacenter (en tout cas plusieurs machines) afin de permettre l'exécution d'applications sur un système distribué.\n\nAinsi, Apache Mesos gère les ressources dont vos applications ont besoin telles que le CPU, la RAM, les IO pour stockage de données, etc ...\n\nMesosphere vient ensuite avec la couche OS s'appuyant sur Apache Mesos permettant de gérer au mieux vos applications et vos ressources.\n\n## Neha Narkhede  - Co-créatrice d'Apache Kafka et CTO de Confluent\n\nNeha dans ce talk nous a présenté pourquoi et comment passer d'un système d'information en \"spaghetti\" (avec des échanges de flux entre toutes les applications, bases de données et autres) en un système d'information centralisé grâce à Apache Kafka.\n\nApache Kafka va en effet permettre de centraliser tous les événements déclenchés par vos applications et de permettre aux applications ou encore bases de données ou outils variés de réagir au déclenchement de ceux-ci. Les échanges de votre SI seront ainsi beaucoup mieux organisés et surtout il vous sera plus simple de les suivre.\n\nL'exemple devient beaucoup plus parlant lorsque Neha s'appuie sur le cas de LinkedIN qui échange plus de 1 400 000 000 000 d'événements par jour.\n\nDe plus, l'usage d'Apache Kafka devient de plus en plus simple grâce à son API d'interconnexion qui dispose aujourd'hui d'un grand nombre de connecteurs tels que Cassandra, Oracle, ElasticSearch, Mysql, MongoDB, Hadoop, ...\n\n*Les slides sont à disposition ici* : [https://speakerdeck.com/nehanarkhede/the-rise-of-real-time](https://speakerdeck.com/nehanarkhede/the-rise-of-real-time){:rel=\"nofollow noreferrer\"}\n\n## Adrian Cole - Lead de Zipkin\n\nCe talk d'Adrian portait sur les 3 éléments clés permettant de surveiller vos applications :\n\n* Logger : le fait d'enregistrer les événements de vos applications,\n* Ajouter des métriques : le fait de combiner des données afin d'obtenir une tendance,\n* Tracer : pour identifier les causes entre les services interagissant avec votre application.\n\nPour l'action de logger, il convient de bien structurer le format de vos logs afin de vous permettre de les exploiter au mieux.\n\nLes métriques, quant à elles, sont simplement un nombre indicateur apparaissant à un moment donné. Il est donc important d'avoir l'association de temps avec cette donnée.\n\nEnfin, il vous faudra passer un identifiant unique de requête entre toutes vos dispositions afin de tracer les échanges entre vos applications.\n\n*Les slides sont à disposition ici* : [https://speakerdeck.com/adriancole/observability-3-ways-logging-metrics-and-tracing](https://speakerdeck.com/adriancole/observability-3-ways-logging-metrics-and-tracing){:rel=\"nofollow noreferrer\"}\n\n## Ulf Adams - Lead de Bazel\n\nBazel est le système de build utilisé par Google sur une petite partie de ses applications pour répondre à une problématique de temps de builds importants, sur certaines applications dont le code source était un unique repository monolithique.\n\nUlf et son équipe planchent alors sur ce problème de temps de build exponentiel en travaillant en étroite collaboration avec les équipes de développement avec cet outil de build et d'exécution de tests nommé Bazel.\n\nParfois même, il est nécessaire d'ajouter des portions de code spécifique permettant d'améliorer les temps de build.\n\nLe mot de la fin de ce talk était d'essayer de sortir le plus possible les librairies qui peuvent être indépendantes dans votre application afin de ne pas avoir à maintenir une base de code énorme.\n\n## Aish Raj Dahal - Ingénieur chez PagerDuty\n\nCe talk n'est pas évident à retranscrire par écrit car il faut vraiment entendre l'histoire de Aish par soi-même afin de comprendre ce qu'il veut dire.\n\nEn effet, ce talk traitait de la gestion de crise lors d'un incident majeur en production : garder son sang froid et considérer les éléments suivants :\n\n* Quelles sont les actions à prendre en compte ?\n* Comment diviser les tâches dans l'équipe disponible à ce moment là ? Qui fait quoi ?\n* Comment notifier en interne et communiquer au(x) client(s) ?\n* Comment s'y préparer ? et surtout : apprendre de ses erreurs.\n\nJe vous encourage à regarder la vidéo du talk lorsqu'elle sera disponible sur le site des dotConferences car l'orateur était vraiment prenant !\n\n*Les slides sont à disposition ici* : [https://speakerdeck.com/aishraj/chaos-management-during-a-major-incident](https://speakerdeck.com/aishraj/chaos-management-during-a-major-incident){:rel=\"nofollow noreferrer\"}\n\n## Mitchell Hashimoto - Fondateur Hashicorp\n\nDans ce talk, Mitchell a mis l’accent sur l’aspect central du produit de la suite Hashicorp : Vault ([https://www.vaultproject.io](https://www.vaultproject.io)){:rel=\"nofollow noreferrer\"}.\n\nEn effet, dans l’organisation DevOps, ce produit permet de stocker des données de manière sécurisée pour toutes les équipes projet : il permet aussi bien de stocker des clés d’API (qui seront utiles aux développeurs) que des données de configuration réseau (qui dans ce cas sera utile pour les Ops).\n\nIl met à disposition plusieurs méthodes pour authentifier les accès aux ressources stockées dans Vault comme par exemple le Multi-Factor App ou encore via certificats TLS.\n\nLe stockage des données (encryptées bien sûr) peut ensuite être effectué sur le back-end de votre choix (MongoDB, PostgreSQL, AWS, Consul, ...).\n\nL’objectif principal de ce produit est de donner les moyens aux personnes de sécuriser leurs applications et infrastructures.\n\n*Les slides sont à disposition ici* : [https://speakerdeck.com/mitchellh/scaling-security](https://speakerdeck.com/mitchellh/scaling-security){:rel=\"nofollow noreferrer\"}\n\nPetit fait marquant pour l’occasion : Mitchell a profité de sa visite à Paris pour demander sa femme en mariage ([https://twitter.com/mitchellh/status/856202103194353664](https://twitter.com/mitchellh/status/856202103194353664)){:rel=\"nofollow noreferrer\"}, tous nos vœux de bonheur !\n\n## James Cammarata - Mainteneur principal d’Ansible\n\nJames a commencé très fort son talk en pointant du doigt les erreurs d’ingénieurs qui ont eu pour effet de causer un début de black-out sur Internet ces dernières années.\n\nComme exemple récent, nous retiendrons la coupure d’une région AWS S3 aux Etats-Unis récemment ([https://aws.amazon.com/fr/message/41926/](https://aws.amazon.com/fr/message/41926/)){:rel=\"nofollow noreferrer\"} dont l’erreur était clairement humaine. Un employé était en effet en train de débugger sur le système de paiement d’AWS et a voulu couper un serveur afin d’effectuer un test. Malheureusement, il y a eu un “effet domino” qui a causé l’arrêt de tous les serveurs AWS S3 de toute une région.\n\nLe talk s’est ensuite recentré sur Ansible et les moyens que nous avons à notre disposition afin d’éviter ce genre de problème.\n\nPar exemple, n’écrivez jamais ce genre de ligne :\n\n```\n- name: Removes backup directory.\n  shell: rm -rf /{{ backup_directory }}\n```\n\nDans ce cas, si la variable \"backup_directory\" n’est pas définie, les données de votre disque seront effacées. Préférez l’utilisation du module “file” d’Ansible qui s’occupera, lui, de faire la vérification que la commande est cohérente.\n\nD’autres cas d’erreurs sont également possibles et ce sont souvent les variables qui en sont la cause. James invite donc à toujours préfixer les variables utilisées dans le code Ansible.\n\nAutre détail annexe mais “fun” de ce talk : James a développé un module Ansible permettant d’interagir avec l’API Phillips Hue. Si cela vous intéresse, il est disponible à cette URL : [https://github.com/jimi-c/hue](https://github.com/jimi-c/hue){:rel=\"nofollow noreferrer\"}\n\nEnfin, un point important évoqué lors de l’interview qui a suivie : Ansible Tower ([https://www.ansible.com/tower](https://www.ansible.com/tower)){:rel=\"nofollow noreferrer\"} devrait par la suite être disponible en open-source.\n\n## David Mazières - Chief Scientist chez Stellar et Professeur à l’université de Stanford\n\nUn talk très intéressant mais pas forcément évident à suivre pour tout le monde !\n\nEn effet, l’objectif de ce talk était de nous faire prendre conscience du protocole Consensus ([https://fr.wikipedia.org/wiki/Consensus_(informatique)](https://fr.wikipedia.org/wiki/Consensus_(informatique))){:rel=\"nofollow noreferrer\"} et donc d’un monde où tout le monde peut avoir le moyen de vérifier une information.\n\nLe premier exemple dont a parlé David, et qui semble évident, sont les autorités de certification. Aujourd’hui, lorsqu’elles délivrent un certificat, elles sont les seules habilitées à contrôler l’authenticité de celui-ci.\n\nMais qu’adviendrait-il si elles étaient corrompues ? Si Apple fournissait des certificats à la NSA par exemple …\n\nLe protocole, largement utilisé par David -dans la société Stellar pour laquelle il travaille- et particulièrement la façon dont il est appliqué a été expliqué en détail dans ce talk.\n\nPlusieurs autorités sont ainsi capables d’authentifier une information.\n\n## Marco Slot - Ingénieur logiciel chez Citus Data\n\nFort de son expérience chez Citus Data, Marco Slot nous fait part de la difficulté de scaler une base de données SQL, pourtant souvent centrale dans une application. Mais il nous rappelle aussi que difficile n’est pas impossible...\n\nGrâce au système ouvert de PostgreSQL et particulièrement à la mise à disposition d’API permettant de créer des extensions pouvant se brancher à plusieurs niveaux dans l’exécuteur SQL, Marco nous laisse comprendre qu’il est ainsi possible de créer une extension permettant de mettre en place du “sharding” en vue de récupérer des données (par exemple) à partir de plusieurs noeuds PostgreSQL lorsqu’une requête est effectuée.\n\nLa conclusion de ce talk est sans appel : PostgreSQL, grâce à son système d’extension, ne se cantonne plus à la fonction de simple base de données, mais devient ainsi une plateforme SQL extensible, et surtout scalable.\n\n*Les slides sont à disposition ici* : [https://speakerdeck.com/marcocitus/scaling-out-postgre-sql](https://speakerdeck.com/marcocitus/scaling-out-postgre-sql){:rel=\"nofollow noreferrer\"}\n\n## Andrew Shafer - Directeur de technologie chez Pivotal\nCe talk est presque de nature philosophique. Pour autant, les propos avancés sont assez denses.\n\nCette présentation sur le DevOps en général et les termes à la mode comme les “micro-services” nous démontraient qu’il n’est pas possible de pratiquer correctement ces méthodologies sans changer d’organisation et de méthodes de travail.\n\nEn effet, voici une liste de quelques termes définissant ce que les gens souhaitent lorsqu’ils parlent de DevOps, selon Andrew : évolutivité, disponibilité, fiabilité, opérabilité, facilité d’utilisation, le tout gratuitement, et sans rien changer.\n\nVous en conviendrez, les deux derniers termes sont bien sûr très compliqués à obtenir, et surtout, il ne sont pas possible sans toucher aux deux parties essentielles : le logiciel et l’humain. Les deux vont de paire pour réussir à adopter ces concepts.\n\nIl définit alors la méthodologie “Calms” pour arriver à pratiquer correctement ces concepts: “Culture, Automation, Lean, Metrics, Sharing”.\n\n*Les slides sont à disposition ici* : [https://www.slideshare.net/littleidea/the-end-of-the-beginning-devopsdays-denver-2017](https://www.slideshare.net/littleidea/the-end-of-the-beginning-devopsdays-denver-2017){:rel=\"nofollow noreferrer\"}\n\n## Clay Smith - Technologue chez New Relic\n\nClay s’est amusé dans ce talk a rechercher le serveur dans le “serverless”.\n\nEn effet, il s’est basé sur les Lambdas d’AWS afin de déterminer de quelles façons elles étaient exécutées.\n\nSes trouvailles sont assez intéressantes : en exécutant un bout de code NodeJS, il a ainsi pu obtenir l’utilisateur courant sur le serveur et même plus : des informations provenant de `/proc`.\n\nNous pouvons donc savoir que les serveurs sur lesquels tournent nos Lambdas (serverless) ont en fait les caractéristiques suivantes (équivalent à peu près à un serveur EC2 de type c4.large) :\n\n* Processeur : 2x Intel(R) Xeon(R) CPU E5-2666 v3 @ 2.90 Ghz\n* Mémoire vive : 3857664 KB (soit environ 4 GO de ram)\n* Interface réseau : 10 Gbps\n\nChaque Amazon Lambda pouvant prendre de 128 MO à 1,5 GO de mémoire vive (et un temps d’exécution maximum de 5 minutes), cela vous laisse imaginer le nombre de machines nécessaires pour faire tourner vos lambdas.\n\nClay montre également que le temps d’exécution varie entre la première lambda et les autres appelées en callback (lorsqu’elles sont déjà initialisées). Il y a donc un laps de temps alloué à l’instanciation des lambdas.\n\nIl conclut ensuite sur le fait qu'idéalement les lambdas sont à utiliser lorsque vous avez des traitements importants à effectuer, de façon occasionnelle en réponse à un événement bien défini qui n’est pas sensible à un temps de latence.\n\n*Les slides sont disponibles ici* : [https://speakerdeck.com/smithclay/searching-for-the-server-in-serverless](https://speakerdeck.com/smithclay/searching-for-the-server-in-serverless){:rel=\"nofollow noreferrer\"}\n\nÀ lire également, l'article sur comment Clay a pu monter un serveur SSH sur une lambda : [https://medium.com/clog/ssh-ing-into-your-aws-lambda-functions-c940cebf7646](https://medium.com/clog/ssh-ing-into-your-aws-lambda-functions-c940cebf7646){:rel=\"nofollow noreferrer\"}\n\n# Conclusion\n\nNous avons passé une très bonne journée, intense en informations. Les conférences très techniques n'étaient pas forcément évidentes à suivre mais étaient pour autant très intéressantes, et si elles n'arrivent pas toujours à convaincre, elles ont au moins le mérite de faire réfléchir.\n\nÀ l'année prochaine !\n"}