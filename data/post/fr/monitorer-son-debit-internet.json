{"date":"2020-09-23T00:00:00.000Z","title":"Monitorer son débit internet\n","excerpt":"Voyons ensemble comment monitorer son débit internet avec un Raspberry Pi\n","readingTime":"10mn","authors":["VEBERArnaud"],"categories":[],"content":"\n## Le projet\nIl y a quelques mois j'ai changé de contrat internet à mon domicile, passant par la même occasion sur la fibre.\nPassé l'excitation d'une connexion beaucoup plus rapide, j'ai commencé à ressentir de la frustration à la moindre petite\nlatence.\nPar ~~conscience scientifique~~ curiosité, j'ai voulu déterminer si ces latences étaient psychologiques ou bien réelles en\ntestant régulièrement ma connexion internet avec [speedtest.net](https://speedtest.net) pour finalement me dire qu'une\nautomatisation était certainement possible.\n\nAprès quelques recherches et la découverte de l'utilitaire [speedtest-cli](https://www.speedtest.net/apps/cli), le projet\nétait lancé.\n\nL'objectif étant de récupérer à intervalle régulier, d'historiser et de consulter ces mesures.\n\n![]({{site.baseurl}}/assets/2020-09-23-monitorer-son-debit-internet/dashboard.png)\n\n## Architecture globale du projet\nNotre projet se décompose en deux parties : d'une part le stockage et la visualisation des métriques, et d'autre part\nla récupération de ces métriques.\nLe tout sera hébergé sur un Raspberry Pi avec docker et docker-compose.\n\n![]({{site.baseurl}}/assets/2020-09-23-monitorer-son-debit-internet/schema.png)\n\nPour la première partie, stockage et visualisation des métriques, nous allons utiliser InfluxDB et Grafana.\nInfluxDB est une base de données time series conçue pour supporter des charges soutenues en lecture et en écriture.\nGrafana est une solution d'analyse et de monitoring supportant de nombreuses sources de données.\n\nPour la seconde partie, récupération des métriques, nous allons utiliser notre version conteneurisée de speedtest-cli.\nL'exécution de cette tache sera planifiée pour un lancement toutes les 10 minutes à l'aide d'un cron job sur le\nraspberry pi.\n\nLes présentations étant faites, enchaînons directement avec la création des composants de notre projet.\n\n## Stockage et visualisation des métriques\nVoyons tout de suite la stack docker-compose permettant la mise en place de la partie stockage et\nvisualisation, puis prenons le temps de la comprendre.\n\n`./docker-compose.yaml`\n```yaml\nversion: \"3.7\"\n\nservices:\n  grafana:\n    image: grafana/grafana:7.1.5\n\n    volumes:\n      - \"grafana-storage:/var/lib/grafana\"\n\n    networks:\n      - speedtest\n    ports:\n      - \"3000:3000\"\n\n  influxdb:\n    image: influxdb:1.8.2\n\n    volumes:\n      - \"influxdb-data:/var/lib/influxdb\"\n\n    networks:\n      - speedtest\n    expose:\n      - \"8086\"\n\nnetworks:\n  speedtest:\n    name: speedtest\n    driver: bridge\n\nvolumes:\n  grafana-storage:\n  influxdb-data:\n```\n\nCette stack docker-compose en version `\"3.7\"` définit nos deux services, `grafana` et `influxdb`.\nElle définit également deux volumes `grafana-storage` et `influxdb-data`, et un network `speedtest` en bridge.\n\nLe service `grafana` lance un conteneur Docker basé sur l'image officielle `grafana/grafana` en version `7.1.5`,\nattache le volume `grafana-storage` au point de montage `/var/lib/grafana` pour la persistance des données de\nconfiguration de Grafana, utilise le réseau `speedtest` et mappe le port `3000` de l'hôte (le raspberry pi) au port\n`3000` du conteneur (Grafana) nous permettant ainsi d'atteindre l'interface de Grafana via l'url\n`http://<ip_raspberry_pi>:3000/`.\n\nLe service `influxdb` lance un conteneur Docker basé sur l'image officielle `influxdb` en version `1.8.2`,\nattache le volume `influxdb-data` au point de montage `/var/lib/influxdb` permettant la persistance des données, et\nexpose le port `8086` dans le réseau `speedtest` permettant une communication interne dans ce réseau via le hostname\n`influxdb`.\n\n> Les versions d'images ont été pinnées `majeur.mineur.patch` pour faciliter le suivi de la partie pratique en éliminant\n> les soucis de compatibilité des futures versions, mais rien n'oblige à rester sur ces versions si les compatibilités\n> sont vérifiées.\n\nDémarrons maintenant cette stack docker-compose avec la commande :\n```bash\ndocker-compose up -d\n```\n\nPuis vérifions que vos 2 conteneurs sont bien au statut `Up` avec la commande.\n```bash\ndocker-compose ps\n\n        Name                  Command           State    Ports\n----------------------------------------------------------------\nspeedtest_grafana_1    /run.sh                  Up      3000/tcp\nspeedtest_influxdb_1   /entrypoint.sh influxd   Up      8086/tcp\n```\n\nMaintenant que notre stack stockage et visualisation est démarrée, intéressons-nous à la partie récupération des\nmétriques.\n\n## Récupération des métriques\nComme annoncé précédemment, nous allons ici utiliser notre propre image Docker embarquant speedtest-cli.\n\n### Docker entrypoint\nCommençons par créer notre script bash servant d'entrypoint Docker et qui sera en charge de l'exécution de speedtest-cli,\nde l'extraction des informations qui nous intéressent, puis de l'envoi des métriques à InfluxDB.\n\n`./docker-entrypoint.sh`\n```bash\n#!/usr/bin/env bash\n\n# InfluxDB variables\ninfluxdb_proto=${INFLUXDB_PROTO:-http}\ninfluxdb_host=${INFLUXDB_HOST:-influxdb}\ninfluxdb_port=${INFLUXDB_PORT:-8086}\ninfluxdb_db=${INFLUXDB_DB:-speedtest}\n\ninfluxdb_url=\"${influxdb_proto}://${influxdb_host}:${influxdb_port}\"\n\n# run speedtest & store result\njson_result=$(speedtest -f json --accept-license --accept-gdpr)\n\n# Extract data from speedtest result\nresult_id=$(echo \"${json_result}\" | jq -r '.result.id')\nping_latency=$(echo \"${json_result}\" | jq -r '.ping.latency')\ndownload_bandwidth=$(echo \"${json_result}\" | jq -r '.download.bandwidth')\nupload_bandwidth=$(echo \"${json_result}\" | jq -r '.upload.bandwidth')\n\n# Ensure InfluxDB database exists\ncurl \\\n    -d \"q=CREATE DATABASE ${influxdb_db}\" \\\n    \"${influxdb_url}/query\"\n\n# Write metric to InfluxDB\ncurl \\\n    -d \"speedtest,result_id=${result_id} ping_latency=${ping_latency},download_bandwidth=${download_bandwidth},upload_bandwidth=${upload_bandwidth}\" \\\n    \"${influxdb_url}/write?db=${influxdb_db}\"\n```\n\nOn commence par définir les variables permettant la communication avec InfluxDB :\n- `influxdb_proto`: le protocole de communication avec InfluxDB, par défaut `http`, surchargeable par la variable\nd'environnement `INFLUXDB_PROTO`\n- `influxdb_host`: le hostname du conteneur InfluxDB, par défaut `influxdb`, surchargeable par la variable\nd'environnement `INFLUXDB_HOST`\n- `influxdb_port`: le port d'écoute du conteneur InfluxDB, par défaut `8086`, surchargeable par la variable\nd'environnement `INFLUXDB_PORT`\n- `influxdb_db`: le nom de la base de données InfluxDB à utiliser, par défaut `speedtest`, surchargeable par la variable\nd'environnement `INFLUXDB_DB`\n\nL'ensemble de ces variables étant ensuite concaténé afin de produire l'url permettant la communication avec InfluxDB\n\nEnsuite on stocke dans une variable le résultat de la commande speedtest exécutée avec les options et arguments :\n- `-f json`: spécifie le format de retour à `json`, nous facilitant l'extraction par la suite\n- `--accept-license`: pour accepter en non interactif la license d'utilisation speedtest/Ookla\n- `--accept-gdpr`: pour accepter en non interactif les conditions de conservation/utilisation des résultats par\nspeedtest/Ookla\n\nUne fois notre résultat récupéré, nous utilisons l'utilitaire `jq` pour extraire les informations qui nous intéressent :\n- `result_id`: l'id unique du test chez Speedtest/Ookla\n- `ping_latency`: la latence du ping en millisecondes\n- `download_bandwidth`: le débit descendant de notre connexion internet en bytes par secondes\n- `upload_bandwidth`: le débit montant de notre connexion internet en bytes par secondes\n\nMaintenant que nous avons toutes les informations qui nous intéressent dans des variables, assurons-nous que la base de\ndonnées InfluxDB `speedtest` existe en forçant la création si celle-ci n'existe pas en exécutant la query\n`CREATE DATABASE ${influx_db}` sur le endpoint `/query` d'InfluxDB.\n\nPuis pour finir écrivons dans cette base de données nos résultats sur le endpoint `/write` d'InfluxDB en précisant le\nnom de notre base de données `?db=${influxdb_db}`, avec la data\n`speedtest,result_id=${result_id} ping_latency=${ping_latency},download_bandwidth=${download_bandwidth},upload_bandwidth=${upload_bandwidth}`\n\n> Plus d'informations sur l'écriture dans InfluxDB sont disponibles dans la\n> [documentation officielle](https://docs.influxdata.com/influxdb/v1.8/guides/write_data/)\n\nAjoutons ensuite les droits d'exécution sur ce script avec la commande `sudo chmod +x ./docker-entrypoint.sh`.\n\nNotre entrypoint est prêt, passons maintenant à la création de l'image Docker responsable de l'exécution de ce script\n\n### Dockerfile\nLa documentation d'[installation](https://www.speedtest.net/fr/apps/cli#installation) de speedtest-cli donne des\ninstructions pour Debian, nous allons donc partir d'une image debian pour créer la nôtre et nous inspirer de\ncette documentation d'installation en l'adaptant à notre cas.\n\n`./Dockerfile`\n```dockerfile\nFROM debian:buster-slim\n\nENV INSTALL_KEY 379CE192D401AB61\nENV DEB_DISTRO buster\n\n# install requirements curl & jq\nRUN apt-get update && apt-get install -y curl jq\n\n# install speedtest\nRUN apt-get update && apt-get install -y gnupg1 apt-transport-https dirmngr && \\\n        apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $INSTALL_KEY && \\\n        echo \"deb https://ookla.bintray.com/debian ${DEB_DISTRO} main\" | tee /etc/apt/sources.list.d/speedtest.list && \\\n        apt-get update && \\\n        apt-get install speedtest\n\nCOPY docker-entrypoint.sh /usr/local/bin\nENTRYPOINT [\"/usr/local/bin/docker-entrypoint.sh\"]\n```\n\nNous partons donc d'une image officielle `debian` en version `buster-slim`, la slim étant largement suffisante\npour notre projet tout en préservant l'espace disque si précieux de notre raspberry pi.\n\nDéfinissons ensuite quelques variables d'environnements :\n- `INSTALL_KEY`: récupérée de la documentation d'installation de speedtest-cli.\n- `DEB_DISTRO`: pour supprimer l'étape `lsb_release -sc` de la documentation d'installation speedtest-cli étant donné\nque l'on connaît la distribution debian utilisée via sa version.\n\nOn installe ensuite les paquets requis (`curl`, `jq`) par notre script bash d'entrypoint.\n\nEnsuite on installe `speedtest-cli`, inspirée par la documentation d'installation speedtest-cli mais adaptée pour\ndocker.\n\nEt pour finir on copie notre script bash `docker-entrypoint.sh`, dans l'image et on indique que ce script sert\nd'entrypoint.\n\nPassons au build de notre image Docker avec la commande\n\n```bash\ndocker build -t docker.local/speedtest:buster-slim .\n```\n\nNotre système de récupération, extraction et écriture étant prêt, passons maintenant à la planification de cette taâche.\n\n### Cron Job\nAprès de multiples tests de résolution (toutes les heures, toutes les demi-heures, toutes les minutes, ...), je me suis\narrêté sur une mesure toutes les 10 minutes qui permet une bonne visibilité sans trop charger le réseau. Pour cela nous\nallons ajouter un cron job sur notre raspberry pi.\n\nUtilisez la commande\n```bash\ncrontab -e\n```\n\nEt ajoutez en fin de fichier la ligne suivante avant de sauvegarder\n```\n*/10 * * * * /usr/bin/docker run --rm --network speedtest docker.local/speedtest:buster-slim\n```\n\nCela signifie que toutes les 10 minutes (`*/10 * * * *`), la commande\n`/usr/bin/docker run --rm --network speedtest docker.local/speedtest:latest` sera exécutée. Cette commande ayant pour\nresponsabilité de démarrer un conteneur Docker depuis l'image précédemment créée `docker.local/speedtest:latest` dans le\nréseau `speedtest` (pour la communication avec `influxdb`) puis de supprimer le conteneur (`--rm`) une fois l'exécution\nterminée.\n\n## Configuration de grafana\nLa dernière étape de notre projet consiste à configurer notre Grafana en :\n- se connectant à l'interface web\n- ajoutant `influxdb` comme source de données\n- créant un dashboard pour une meilleure visualisation des données de la source `influxdb`\n\n### Connexion à l'interface web\n\nPour vous connecter a l'interface web de Grafana, rendez vous à l'url `http://<ip_raspberry_pi>:3000/`.\n\nUn écran de connexion s'affiche, utilisez le username `admin` et le mot de passe `admin` pour votre première connexion.\nVous serez ensuite redirigé vers une page vous permettant de changer le mot de passe de l'utilisateur `admin`.\n\n![]({{site.baseurl}}/assets/2020-09-23-monitorer-son-debit-internet/grafana_connect.gif)\n\n### Source de donnée InfluxDB\n\nIntéressons-nous maintenant à la configuration de la data source InfluxDB dans Grafana.\n\nDepuis l'accueil de Grafana, sélectionnez `Add your first data source` ou rendez-vous à l'url\n`http://<ip_raspberry_pi>:3000/datasources/new`.\n\nSélectionnez ensuite `InfluxDb`.\n\nSur la page configuration de la data source, il faut renseigner l'url `http://influxdb:8086` dans la section \"HTTP\", puis\nrenseigner le nom de la base de données `speedtest` dans la section \"InfluxDB Details\".\n\nVous pouvez alors sauvegarder et tester la connexion (bouton \"Save & Test\").\n\n![]({{site.baseurl}}/assets/2020-09-23-monitorer-son-debit-internet/grafana_datasource.gif)\n\n### Création du dashboard\n\nPour la configuration du dashboard, on va importer directement le json que j'ai exporté de mon installation.\n\nDans le menu survolez le `+` (Create) puis sélectionnez \"Import\".\n\nRécupérez le json dans ce [gist](https://gist.github.com/VEBERArnaud/4d37935fe906324dd18ff01cb511eda6) et collez le dans\nla zone \"Import via panel json\" puis chargez le (bouton \"Load\").\n\nEt enfin importez le (bouton \"Import\").\n\n![]({{site.baseurl}}/assets/2020-09-23-monitorer-son-debit-internet/grafana_dashboard.gif)\n\n## Conclusion\nEn quelques minutes nous avons mis en place une solution permettant de monitorer votre débit internet. Cependant cette\nsolution peut être améliorée.\nJe pense par exemple à la multiplication des mesures en augmentant le nombre de serveurs de tests pour ne pas toujours\nme fier au serveur sélectionné automatiquement par speedtest-cli (voir `speedtest -L`).\n\nN'étant pas totalement satisfait de la méthode utilisée pour les mesures je ne me lancerai pas dans une analyse des\nrésultats, mais libre à chacun de les interpréter comme il le souhaite.\n"}