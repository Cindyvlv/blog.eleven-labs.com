{"date":"2017-10-17T00:00:00.000Z","title":"HTTPS, S3, CDN: des nouvelles du blog\n","excerpt":"De Github Pages à Amazon Web Services, cet article est un retour d'expérience/tutorial de notre changement d'hébergement pour le blog.","readingTime":"17mn","authors":["VEBERArnaud"],"categories":["architecture"],"content":"\nEn Juillet dernier nous vous annoncions la\n[refonte du blog]({{ '/fr/migration-du-blog/' | prepend: site.baseurl | replace: '//', '/' }}) en Jekyll hébergé sur\ngithub pages.\nCependant, l'hébergement sur github pages ne permet pas l'utilisation d'un certificat SSL autre que celui fourni.\nCe certificat étant prévu pour une utilisation sur le domaine `github.io`, nous ne pouvions pas l'utiliser avec notre\ndomaine `eleven-labs.com`.\n\nDans ce post, je vais vous expliquer les modifications que nous avons faites afin d'utiliser Amazon Web Services pour\nl'hébergement en https tout en conservant notre stratégie de déploiement continu.\n\nLes services AWS que nous utilisons pour cela sont :\n- [AWS Certificate Manager](https://aws.amazon.com/fr/certificate-manager/){:rel=\"nofollow noreferrer\"}\n- [Amazon S3](https://aws.amazon.com/fr/s3/){:rel=\"nofollow noreferrer\"}\n- [Amazon Cloudfront](https://aws.amazon.com/fr/cloudfront/){:rel=\"nofollow noreferrer\"}\n\n> Pour simplifier les interactions avec AWS, nous allons utiliser `aws-cli` afin de ne pas nous perdre dans son interface\n> web chargée.\n> Un [guide d'installation](http://docs.aws.amazon.com/fr_fr/cli/latest/userguide/installing.html){:rel=\"nofollow noreferrer\"} est disponible sur la\n> [documentation officielle](https://aws.amazon.com/fr/documentation/){:rel=\"nofollow noreferrer\"}.\n\n## Mise en place du certificat SSL/TLS avec AWS Certificate Manager\n\nPour le certificat SSL/TLS, nous utilisons le service AWS Certificate Manager.\nCe service gratuit permet la mise en place et le renouvellement automatiques de certificats SSL/TLS utilisables avec les\nservices AWS.\n\n### Demande de certificat\n\nLes demandes de certificat via `aws-cli` s'effectuent grâce à la commande `aws acm request-certificate` à laquelle il faut\npréciser le nom domaine via l'option `--domain-name`.\nIl est également possible de renseigner les options `--subject-alternative-names`, `--idempotency-token` et\n`--domain-validation-options`.\n\nDans notre cas la commande est :\n\n```bash\naws acm request-certificate --domain-name \"blog.eleven-labs.com\" --region \"us-east-1\"\n```\n\n> La subtilité de cette étape consiste à faire la demande de certificat dans la région us-east-1 (N. Virginia), sinon\n> le certificat ne pourra pas être utilisé sur la future distribution Amazon Cloudfront.\n\n### Validation de la propriété du domaine\n\nAvant que l'autorité de certification d'Amazon puisse émettre le certificat, AWS Certificate Manager doit vérifier que\nvous possédez ou contrôlez tous les domaines que vous avez indiqués dans la demande.\nAmazon Certificate Manager effectue cela en envoyant un e-mail de validation de domaines aux adresses qui sont\nenregistrées pour les domaines.\nPour chaque nom de domaine que vous incluez dans votre demande de certificat, un e-mail est envoyé à 3 adresses de\ncontact dans WHOIS et 5 adresses d'administration système courantes pour votre domaine.\nAinsi, jusqu'à 8 messages électroniques seront envoyés pour chaque nom de domaine que vous spécifiez dans votre demande.\nPour valider, vous devez donner suite à 1 de ces 8 messages dans un délai de 72 heures.\n\nCet e-mail est envoyé aux trois adresses de contact suivantes dans WHOIS :\n- Propriétaire du domaine\n- Contact technique\n- Contact administratif\n\nL'e-mail est également envoyé aux cinq adresses d'administration système courantes suivantes :\n- administrator@votre_domaine\n- hostmaster@votre_domaine\n- postmaster@votre_domaine\n- webmaster@votre_domaine\n- admin@votre_domaine\n\n## Déploiement sur Amazon S3 avec Travis CI\n\nPour l'hébergement de notre blog Jekyll buildé, nous avons opté pour Amazon S3.\nAmazon S3 pour Simple Storage Service, est un service de stockage d'objets qui peut-être configuré pour servir les\nobjets du bucket comme site web statique.\nCette solution est idéale dans notre cas car une fois buildé, le blog est un ensemble de fichiers statiques qui peuvent\nêtre servis tels quels, nous évitant ainsi l'utilisation et les coûts d'une VM de type EC2 qui n'aurait servi qu'à\nhéberger un serveur web.\n\n### Création du bucket S3\n\nLa première étape consiste à créer le bucket S3 qui stockera nos fichiers statiques buildés.\nPour cela on utilise la\ncommande `aws s3api create-bucket` à laquelle il faut préciser le nom du bucket via l'option `--bucket`.\n\n> La subtilité de cette étape, consiste a nommer le bucket comme le FQDN du site.\n> Dans notre cas, le site doit être accessible à l'url `blog.eleven-labs.com`, le bucket doit donc être nommé\n> `blog.eleven-labs.com`\n\nLa commande à exécuter dans notre cas est :\n\n```bash\naws s3api create-bucket --bucket \"blog.eleven-labs.com\"\n```\n\n### Configuration du bucket en site web\n\nLa seconde étape est la configuration du bucket en site web statique.\nNous utilisons ce coup-ci la commande `aws s3api put-bucket-website` en lui précisant le nom du bucket via l'option\n`--bucket` ainsi qu'un peu de configuration pour notre site web avec l'option `--website-configuration` à laquelle il\nfaut fournir un fichier json.\n\n*fichier: blog_eleven-labs_com.s3.json*\n```json\n{\n    \"ErrorDocument\": {\n        \"Key\": \"404.html\"\n    },\n    \"IndexDocument\": {\n        \"Suffix\": \"index.html\"\n    }\n}\n```\n\nDans la configuration du site web, nous renseignons la clé du fichier d'erreur (`ErrorDocument`) ainsi que le suffixe\ndes documents d'index (`IndexDocument`).\nIl est ici question de suffixe car un bucket S3 n'est pas un système de fichier, tous les documents sont à plat et les\nslashs `/` font partie intégrante du nom de fichier, on parle alors de clé.\nCe système permet de simuler la fonctionnalité de `DirectoryIndex` de la plupart des serveurs web traditionnels.\n\nNous utilisons alors la commande :\n\n```bash\naws s3api put-bucket-website --bucket \"blog.eleven-labs.com\" --website-configuration file://blog_eleven-labs_com.s3.json\n```\n\n### Autorisation d'accès publique en lecture seule aux objets du bucket\n\nMaintenant que notre bucket est configuré en tant que site web, il faut également que l'on autorise un accès publique en\nlecture aux objets qui se trouvent à l'intérieur.\nPour cela nous utilisons une `policy` que nous attachons au bucket via la commande `aws s3api put-bucket-policy` à\nlaquelle nous précisons le bucket via l'option `--bucket` ainsi que la policy en json inline dans l'option `--policy`.\n\n```json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"PublicReadGetObject\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:GetObject\",\n            \"Resource\": \"arn:aws:s3:::blog.eleven-labs.com/*\"\n        }\n    ]\n}\n```\n\nCette policy autorise (`Allow`) un accès en lecture seule (`s3:GetObject`) sur tous les objets du bucket\n(`arn:aws:s3:::blog.eleven-labs.com/*`) et à tout le monde (`*`).\n\n```bash\naws s3api put-bucket-policy --bucket \"blog.eleven-labs.com\" --policy \"{\\\"Version\\\":\\\"2012-10-17\\\",\\\"Statement\\\":[{\\\"Sid\\\":\\\"PublicReadGetObject\\\",\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\\\"arn:aws:s3:::blog.eleven-labs.com/*\\\"}]}\"\n```\n\n### Déploiement depuis Travis CI\n\nNotre bucket est maintenant prêt à servir le blog, il ne nous reste plus qu'à y uploader les fichiers buildés à chaque\nmerge sur la branche master du [repository](https://github.com/eleven-labs/blog.eleven-labs.com){:rel=\"nofollow noreferrer\"} grâce à Travis CI.\nNous utilisons déjà Travis CI pour l'intégration et le déploiement continus du blog, notamment pour la\n[vérification de l'orthographe]({{ '/fr/comment-verifier-l-orthographe-de-vos-docs-depuis-travis-ci/' | prepend: site.baseurl | replace: '//', '/' }})\ndans les PR mais également la création et l'upload à Algolia des données permettant la recherche dans le blog.\n\nPour le déploiement du blog dans notre bucket S3, il a suffit d'ajouter deux étapes au fichier de configuration\n`.travis.yml`.\nL'étape `before_deploy` qui permet de préparer le déploiement et l'étape `deploy` qui effectue le déploiement.\n\n```yml\n# .travis.yml\n\n#...\n\nbefore_deploy:\n    - bundle exec jekyll build\n    - pip install --user awscli\n    - aws s3 rm s3://blog.eleven-labs.com --recursive\n\ndeploy:\n    - provider: s3\n      access_key_id: $AWS_ACCESS_KEY_ID\n      secret_access_key: $AWS_SECRET_ACCESS_KEY\n      region: $AWS_DEFAULT_REGION\n      bucket: blog.eleven-labs.com\n      local_dir: _site\n      skip_cleanup: true\n      on:\n          branch: master\n\n#...\n\n```\n\nDans l'étape de préparation du déploiement, nous buildons les fichiers statiques (`bundle exec jekyll build`) puis nous\ninstallons l'outil aws-cli afin de vider le bucket avant le déploiement (`aws s3 rm s3://blog.eleven-labs.com\n--recursive`)\n\nDans l'étape de déploiement, nous utilisons le provider s3 supporté nativement par travis pour uploader les fichiers\nbuildés.\nCette étape ainsi que l'étape de préparation du déploiement ne sont déclenchées que pour la branche master.\n\n## Mise en place de Amazon CloudFront\n\nL'autre modification que nous avons apportée à l'architecture du blog est l'ajout d'une distribution Amazon Cloudfront,\ncela permet une amélioration des temps de réponse grâce à une augmentation des points de présence.\nMais cela nous a également permis d'utiliser le protocole http2 ainsi que le certificat SSL/TLS que nous avons généré au\ndébut de l'article.\n\n### Création de la distribution Cloudfront\n\nLa commande permettant la création d'une distribution Amazon Cloudfront est `aws cloudfront create-distribution` à\nlaquelle on fournit un fichier json de configuration via l'option `--distribution-config`.\n\n> La subtilité de cette étape, consiste à utiliser une `CustomOriginConfig` à la place d'une `S3OriginConfig`.\n> Cela permet de profiter de la fonctionnalité S3 simulant le `DirectoryIndex` étant donné que l'on utilise directement\n> le site servi par S3 au lieu du contenu du bucket.\n\n*fichier: blog_eleven-labs_com.cloudfront.json*\n\n```json\n{\n    \"CallerReference\": \"1504193163145\",\n    \"Aliases\": {\n        \"Quantity\": 1,\n        \"Items\": [\n            \"blog.eleven-labs.com\"\n        ]\n    },\n    \"DefaultRootObject\": \"index.html\",\n    \"Origins\": {\n        \"Quantity\": 1,\n        \"Items\": [\n            {\n                \"Id\": \"S3-Website-blog.eleven-labs.com.s3-website.eu-west-2.amazonaws.com\",\n                \"DomainName\": \"blog.eleven-labs.com.s3-website.eu-west-2.amazonaws.com\",\n                \"OriginPath\": \"\",\n                \"CustomHeaders\": {\n                    \"Quantity\": 0\n                },\n                \"CustomOriginConfig\": {\n                    \"HTTPPort\": 80,\n                    \"HTTPSPort\": 443,\n                    \"OriginProtocolPolicy\": \"http-only\",\n                    \"OriginSslProtocols\": {\n                        \"Quantity\": 3,\n                        \"Items\": [\n                            \"TLSv1\",\n                            \"TLSv1.1\",\n                            \"TLSv1.2\"\n                        ]\n                    },\n                    \"OriginReadTimeout\": 30,\n                    \"OriginKeepaliveTimeout\": 5\n                }\n            }\n        ]\n    },\n    \"DefaultCacheBehavior\": {\n        \"TargetOriginId\": \"S3-Website-blog.eleven-labs.com.s3-website.eu-west-2.amazonaws.com\",\n        \"ForwardedValues\": {\n            \"QueryString\": false,\n            \"Cookies\": {\n                \"Forward\": \"none\"\n            },\n            \"Headers\": {\n                \"Quantity\": 0\n            },\n            \"QueryStringCacheKeys\": {\n                \"Quantity\": 0\n            }\n        },\n        \"TrustedSigners\": {\n            \"Enabled\": false,\n            \"Quantity\": 0\n        },\n        \"ViewerProtocolPolicy\": \"redirect-to-https\",\n        \"MinTTL\": 0,\n        \"AllowedMethods\": {\n            \"Quantity\": 2,\n            \"Items\": [\n                \"HEAD\",\n                \"GET\"\n            ],\n            \"CachedMethods\": {\n                \"Quantity\": 2,\n                \"Items\": [\n                    \"HEAD\",\n                    \"GET\"\n                ]\n            }\n        },\n        \"SmoothStreaming\": false,\n        \"DefaultTTL\": 86400,\n        \"MaxTTL\": 31536000,\n        \"Compress\": true,\n        \"LambdaFunctionAssociations\": {\n            \"Quantity\": 0\n        }\n    },\n    \"CacheBehaviors\": {\n        \"Quantity\": 0\n    },\n    \"CustomErrorResponses\": {\n        \"Quantity\": 1,\n        \"Items\": [\n            {\n                \"ErrorCode\": 404,\n                \"ResponsePagePath\": \"/404.html\",\n                \"ResponseCode\": \"404\",\n                \"ErrorCachingMinTTL\": 300\n            }\n        ]\n    },\n    \"Comment\": \"\",\n    \"Logging\": {\n        \"Enabled\": false,\n        \"IncludeCookies\": false,\n        \"Bucket\": \"\",\n        \"Prefix\": \"\"\n    },\n    \"PriceClass\": \"PriceClass_100\",\n    \"Enabled\": true,\n    \"ViewerCertificate\": {\n        \"ACMCertificateArn\": \"arn:aws:acm:us-east-1:760119988015:certificate/0324426f-d1d5-42b7-8c42-955b131b12ba\",\n        \"SSLSupportMethod\": \"sni-only\",\n        \"MinimumProtocolVersion\": \"TLSv1\",\n        \"Certificate\": \"arn:aws:acm:us-east-1:760119988015:certificate/0324426f-d1d5-42b7-8c42-955b131b12ba\",\n        \"CertificateSource\": \"acm\"\n    },\n    \"Restrictions\": {\n        \"GeoRestriction\": {\n            \"RestrictionType\": \"none\",\n            \"Quantity\": 0\n        }\n    },\n    \"WebACLId\": \"\",\n    \"HttpVersion\": \"http2\",\n    \"IsIPV6Enabled\": true\n}\n```\n\nCréons la distribution Cloudfront avec la commande:\n\n```bash\naws cloudfront create-distribution --distribution-config file://blog_eleven-labs_com.cloudfront.json\n```\n\n### Gestion des invalidations de cache\n\nLe temps de cache par défaut de la distribution Cloudfront étant de 86400 secondes, nous avons maintenant besoin\nd'invalider ce cache à chaque nouveau déploiement.\n\nPour cela nous allons utiliser une nouvelle étape du déploiement avec Travis, le `after_deploy`.\nComme son nom l'indique, cette étape est déclenchée après le `deploy` à condition que celui-ci soit en succès.\n\n```yml\n# .travis.yml\n\n#...\n\nafter_deploy:\n    - aws configure set preview.cloudfront true\n    - aws cloudfront create-invalidation --distribution-id \"$CLOUDFRONT_DISTRIBUTION_ID\" --paths \"/*\"\n\n#...\n```\n\nÀ cette étape, nous utilisons une fois de plus l'outil aws-cli auquel nous précisons que l'on veut utiliser les\nfonctionnalités en preview de la command cloudfront (`aws configure set preview.cloudfront true`), puis nous créons une\ndemande d'invalidation sur l'ensemble du cache (`aws cloudfront create-invalidation --distribution-id\n\"$CLOUDFRONT_DISTRIBUTION_ID\" --paths \"/*\"`).\n`$CLOUDFRONT_DISTRIBUTION_ID` étant une variable définie dans la configuration Travis et contenant l'id de la\ndistribution Cloudfront.\n\n## Conclusion\n\nDepuis la refonte du blog nous n'avons cessé d'améliorer l'expérience utilisateur en intervenant sur les aspects\ngraphiques et fonctionnels du blog, mais également comme nous venons de le voir, sur la sécurité, les performances et les\npossibilités d'évolutions du blog.\n\nTravis CI nous a permis de conserver notre workflow de déploiement continu et Amazon Web Services nous a permis\nd'améliorer les performances et la sécurité grâce à l'utilisation de Cloudfront avec le protocole http2 et de AWS\nCertificate Manager pour le certificat SSL/TLS managé.\nConcernant les possibilités d'évolutions, il y a par exemple une PWA jusque là bloquée par l'absence de certificat SSL.\n\nUn autre point que j'aimerais éclaircir concerne les coûts de cette architecture.\nNous sommes passés d'un hébergement Github Pages gratuit mais qui ne nous satisfaisait pas pleinement, à cette architecture\npayante mais plus flexible et répondant à nos attentes.\nLes coûts de cette architecture sont relativement compliqués à estimer étant donné que la facturation pour les services\nAmazon Cloudfront et Amazon S3 sont principalement liés à l'utilisation.\nL'utilisation de ces services est calculée en fonction du volume de données tranférés pour Cloudfront et du volume de\ndonnées stockées sur S3.\nCette solution reste tout de même économique comparée à un hébergement traditionnel composé de serveurs web sur Amazon EC2,\nauxquels peuvent s'ajouter un load balancer pour les sites ayant un traffic plus soutenu.\n\nCette migration n'a rencontré aucun problème en particulier et s'est déroulée de manière totalement transparente pour\nles utilisateurs, à l'exception de l'utilisation du protocole https, qui était le but recherché.\n\nCette migration a également entraîné la mise en place de \"live preview\" des pull requests, le fonctionnement étant très\nproche de ce que l'on vient de voir ensemble, mais je garde ce sujet pour un potentiel futur article sur notre blog.\n"}