{"date":"2017-12-04T00:00:00.000Z","title":"Deploy a replicated MongoDB on AWS with Terraform and Ansible","excerpt":"I recently had the opportunity to deploy a MongoDB server on Amazon Web Services (AWS). In order to limit the problems of crash and data loss, it is also replicated with two other servers, ideally in a different geographical area to ensure high availability.","readingTime":"12mn","authors":["vcomposieux"],"categories":[],"content":"\nI recently had the opportunity to deploy a MongoDB server on Amazon Web Services (AWS). In order to limit the problems of crash and data loss, it is also replicated with two other servers, ideally in a different geographical area to ensure high availability.\n\nTo automate the creation of EC2 machines, I used [Terraform](https://www.terraform.io/) (and its `aws` provider) as well as Ansible](https://www.ansible.com/) for provisioning. This article describes the technical logic that we set up to achieve this.\n\n## Context\n\nSo we have a MongoDB cluster composed of three EC2 instances (say, `t2. large` type).\n\nAmong these instances, MongoDB will elect a master server, called `primary` in the MongoDB language as well as slave servers, called `secondary`.\n\nIn order for these three servers to share the same data, we will need to create what MongoDB calls a [replica set](https://docs.mongodb.com/manual/tutorial/deploy-replica-set/), a data set.\n\nWhat is important to note is that only the `primary` server will be able to read or write data. The `secondary` servers are there to take over in case the `primary` server is unavailable. This is possible thanks to an election that is launched automatically by MongoDB to elect a new `primary` server.\n\nThis is the target infrastructure we are looking for, for this replication:\n\n![MongoDB Replication](/imgs/posts/2017-11-01-deployer-un-mongodb-replique-sur-aws-avec-terraform-et-ansible/replication.svg)\n\n\nAs you can see on this diagram, only the primary node is used for read/write, the other two replicas are there to synchronize the updated data of the primary server in real time as well as for the purpose of eventually becoming primary in turn, in case the current primary server would become unavailable.\n\nThe definition of a server (primary or secondary) is done through a majority election, which takes place between the servers. Thus, you will necessarily need to have at least three servers so that a majority can be constituted.\n\nIt is therefore impossible to define this replication model with only two servers in your cluster.\n\n## Terraform: server creation\n\nSo let's move on to the creation of machines on AWS: we have made the choice of [Terraform](https://www.terraform.io) for this part, a resource automation tool.\n\nTerraform is therefore a tool for industrializing infrastructure tasks such as, in our case, the creation of EC2 machines on our AWS account.\n\nIn order to create a MongoDB server (let's take the case of a first server), we use the following terraform code:\n\n```\n# EC2 Instance: MongoDB 1\nresource \"aws_instance\" \"mongodb_one\" {\n    availability_zone = \"${var.AWS_REGION}a\"\n\n    tags {\n        Name = \"${var.ENVIRONMENT}-mongodb-one\"\n    }\n\n    ami = \"<your-ami-id>\"\n\n    instance_type = \"t2.large\"\n\n    root_block_device {\n        volume_type = \"gp2\"\n        volume_size = \"100\"\n    }\n\n    security_groups = [\n        \"${aws_security_group.mongodb.name}\"\n    ]\n\n    associate_public_ip_address = true\n\n    key_name = \"id_rsa\"\n}\n```\n\nIn this script, we therefore specify a new resource of the type `aws_instance` and name it `mongodb-one`.\n\nThis instance will be in the area `a` of our AWS region, defined as an environment variable.\n\nWe must also specify the AMI image (Amazon Image) that will be used on this instance. To do this, I invite you to select an AMI identifier from those available on Amazon, using this command via the AWS CLI for example:\n\n```json\n$ aws ec2 describe-images --filters \"Name=root-device-type,Values=ebs\" \"Name=name,Values=ubuntu*hardy*\"\n\n[\n    {\n        \"Architecture\": \"x86_64\",\n        \"CreationDate\": \"2011-10-07T09:09:03.000Z\",\n        \"ImageId\": \"ami-ffecde8b\",\n        \"ImageLocation\": \"063491364108/ubuntu-8.04-hardy-server-amd64-20111006\",\n        \"ImageType\": \"machine\",\n        \"Public\": true,\n        \"KernelId\": \"aki-4cf5c738\",\n        \"OwnerId\": \"063491364108\",\n        \"RamdiskId\": \"ari-2ef5c75a\",\n        \"State\": \"available\",\n        \"BlockDeviceMappings\": [\n            {\n                \"DeviceName\": \"/dev/sda1\",\n                \"Ebs\": {\n                    \"Encrypted\": false,\n                    \"DeleteOnTermination\": true,\n                    \"SnapshotId\": \"snap-eb7aa883\",\n                    \"VolumeSize\": 8,\n                    \"VolumeType\": \"standard\"\n                }\n            },\n            {\n                \"DeviceName\": \"/dev/sdb\",\n                \"VirtualName\": \"ephemeral0\"\n            }\n        ],\n        \"Description\": \"Ubuntu 8.04 Hardy server amd64 20111006\",\n        \"Hypervisor\": \"xen\",\n        \"Name\": \"ubuntu-8.04-hardy-server-amd64-20111006\",\n        \"RootDeviceName\": \"/dev/sda1\",\n        \"RootDeviceType\": \"ebs\",\n        \"VirtualizationType\": \"paravirtual\"\n    }\n    ...\n]\n```\n\nYou will have access to Ubuntu Hardy images supporting Amazon EBS (Elastic Block Storage) volumes.\n\nThe field you will be interested in is `ImageId`, which you must copy into your Terraform code.\n\nWe then specify the type of instance as well as the type of disk and sizing we want to use for our server.\n\nYou will notice that we specify a `security_groups' entry for our instance that is dynamic and actually points to another resource we have to declare.\n\nSo let's declare our security group for this MongoDB server:\n\n```\n# MongoDB security group\nresource \"aws_security_group\" \"mongodb\" {\n  name        = \"mongodb-${var.ENVIRONMENT}\"\n  description = \"Security group for mongodb-${var.ENVIRONMENT}\"\n\n  tags {\n    Name = \"mongodb-${var.ENVIRONMENT}\"\n  }\n}\n\nresource \"aws_security_group_rule\" \"mongodb_allow_all\" {\n  type            = \"egress\"\n  from_port       = 0\n  to_port         = 0\n  protocol        = \"-1\"\n  cidr_blocks     = [\"0.0.0.0/0\"]\n\n  security_group_id = \"${aws_security_group.mongodb.id}\"\n}\n\nresource \"aws_security_group_rule\" \"mongodb_ssh\" {\n  type            = \"ingress\"\n  from_port       = 22\n  to_port         = 22\n  protocol        = \"tcp\"\n  cidr_blocks     = [\"0.0.0.0/0\"]\n\n  security_group_id = \"${aws_security_group.mongodb.id}\"\n}\n\nresource \"aws_security_group_rule\" \"mongodb_mongodb\" {\n  type            = \"ingress\"\n  from_port       = 27017\n  to_port         = 27017\n  protocol        = \"tcp\"\n  cidr_blocks     = [\"0.0.0.0/0\"]\n\n  security_group_id = \"${aws_security_group.mongodb.id}\"\n}\n\nresource \"aws_security_group_rule\" \"mongodb_mongodb_replication\" {\n  type            = \"ingress\"\n  from_port       = 27019\n  to_port         = 27019\n  protocol        = \"tcp\"\n  cidr_blocks     = [\"0.0.0.0/0\"]\n\n  security_group_id = \"${aws_security_group.mongodb.id}\"\n}\n```\n\nHere, a bunch of rules are specified in our security group.\n\nWe need to allow the input ports `22` (SSH), `27017` (default port of MongoDB) and `27019` which is used by MongoDB to manage communication between servers.\n\nYou will notice that we allow here all the provenances in the `cidr_blocks` entry, it is obviously necessary to restrict these accesses as much as possible.\n\nWe are now finished with the Terraform part: we are able to create a MongoDB (EC2) server on AWS but we still have to provision the server.\n\n## Ansible: provisioning\n\nTo provision the MongoDB server, we use an Ansible playbook. Here is the definition of the playbook:\n\n```yaml\n- hosts: db-mongodb\n  become: yes\n  roles:\n  - project.provision.mongodb\n```\n\nThe `db-mongodb` host corresponds to both the primary and secondary servers.\n\nWe distinguish these servers because we need to define a primary server first when we provision the cluster.\n\n```\n# Primary server\n[db-mongodb-master]\n<adresse ip> ansible_user=root\n\n# Secondary servers\n[db-mongodb-slave-1]\n<adresse ip> ansible_user=root\n\n[db-mongodb-slave-2]\n<adresse ip> ansible_user=root\n\n# MongoDB Groups\n[db-mongodb-slave:children]\ndb-mongodb-slave-1\ndb-mongodb-slave-2\n\n[db-mongodb:children]\ndb-mongodb-master\ndb-mongodb-slave\n```\n\nFor the `db-mongodb` host we will therefore play a `project. provision. mongodb` role that we will need to perform the following actions:\n\n* Installation and creation of a MongoDB system service\n* Preparation of the MongoDB configuration file\n* Activation of replication with other hosts\n* Create user accounts\n* Starting the MongoDB instance\n\nSo let's start with the installation and activation of MongoDB:\n\n```yaml\n- name: Install mongodb\n  apt:\n    name: mongodb-org\n    state: present\n    allow_unauthenticated: yes\n\n- name: Create systemd service file\n  template:\n    src: mongod.service\n    dest: /etc/systemd/system/mongodb.service\n\n- name: Enable Mongod service\n  command: systemctl enable mongodb.service\n  become: yes\n  when: env == 'dev'\n```\n\nNothing very special so far. Note that the `mongod. service` file is directly available in our Ansible code and can be variabilized on certain values.\n\nThis is also the case for the MongoDB configuration, which we also import to the server:\n\n```yaml\n- name: Copy MongoDB configuration file\n  template:\n    src: mongod.conf\n    dest: /etc/mongod.conf\n```\n\nIn order to enable replication, note that we need to specify in this configuration file, a set replica name (here, `rs0`):\n\n```yaml\nreplication:\n  replSetName: \"rs0\"\n```\n\nThis replication will work only if the servers are able to communicate with each other.\n\nIt is also important to secure these exchanges, which is why we will create a key to authenticate the servers discussing with one another:\n\n\n```yaml\n- name: Prepare authorization key file\n  local_action: shell openssl rand -base64 756 > {{ playbook_dir }}/passwords/{{ env }}/mongodb-key\n  when: database_replica_type == \"master\"\n\n- name: Create mongodb home directory\n  file:\n    state: directory\n    path: /home/mongodb\n    owner: mongodb\n    group: mongodb\n    mode: 0755\n\n- name: Copies key to both master and slaves\n  copy:\n    src: \"{{ playbook_dir + '/passwords/' + env + '/mongodb-key'}}\"\n    dest: /home/mongodb/mongodb-key\n    owner: mongodb\n    group: mongodb\n    mode: 0400\n  when: database_replica_type != false\n\n- name: Add key to mongodb configuration\n  lineinfile:\n    dest: /etc/mongod.conf\n    state: present\n    regexp: '#  keyFile:'\n    line: '  keyFile: /home/mongodb/mongodb-key'\n    backrefs: yes\n  when: database_replica_type != false\n```\n\n\nWe create here the necessary key with `openssl`, copy it on the servers and specify it in the configuration file (a restart of MongoDB will be necessary to take this key into account).\n\nFinally, let's boot or reboot our MongoDB servers using the system service previously created:\n\n```yaml\n- name: Restart mongodb\n  command: systemctl restart mongodb.service\n```\n\nNow, when you connect to your different MongoDB servers, you will have the `PRIMARY` or `SECONDARY` element in the console, as in the example below, which allows you to know where you are:\n\n```\nroot@mongodb:~# mongo --host localhost -u user -p<password> admin\nMongoDB shell version: 3.2.17\nconnecting to: localhost:27017/admin\nrs0:PRIMARY>\n```\n\nYou can also check the configuration of your replication via the `rs. conf ()` command in the different MongoDB servers:\n\n```\nrs0:PRIMARY> rs.conf()\n{\n\t\"_id\" : \"rs0\",\n\t\"version\" : 3,\n\t\"protocolVersion\" : NumberLong(1),\n\t\"members\" : [\n\t\t{\n\t\t\t\"_id\" : 0,\n\t\t\t\"host\" : \"<ip1>:27017\",\n\t\t\t\"arbiterOnly\" : false,\n\t\t\t\"buildIndexes\" : true,\n\t\t\t\"hidden\" : false,\n\t\t\t\"priority\" : 1,\n\t\t\t\"tags\" : {\n\n\t\t\t},\n\t\t\t\"slaveDelay\" : NumberLong(0),\n\t\t\t\"votes\" : 1\n\t\t},\n\t\t{\n\t\t\t\"_id\" : 1,\n\t\t\t\"host\" : \"<ip2>:27017\",\n\t\t\t\"arbiterOnly\" : false,\n\t\t\t\"buildIndexes\" : true,\n\t\t\t\"hidden\" : false,\n\t\t\t\"priority\" : 1,\n\t\t\t\"tags\" : {\n\n\t\t\t},\n\t\t\t\"slaveDelay\" : NumberLong(0),\n\t\t\t\"votes\" : 1\n\t\t},\n\t\t{\n\t\t\t\"_id\" : 2,\n\t\t\t\"host\" : \"<ip3>:27017\",\n\t\t\t\"arbiterOnly\" : false,\n\t\t\t\"buildIndexes\" : true,\n\t\t\t\"hidden\" : false,\n\t\t\t\"priority\" : 1,\n\t\t\t\"tags\" : {\n\n\t\t\t},\n\t\t\t\"slaveDelay\" : NumberLong(0),\n\t\t\t\"votes\" : 1\n\t\t}\n\t],\n    ...\n```\n\nThus, no more doubt about your configuration. You also have the option of giving weight to certain servers that will allow you to influence the elections of a new primary server in case of a failure on your cluster via the `priority` property.\n\n## Conclusion\n\nDeploying a MongoDB cluster with an active replication on a specified infrastructure via Terraform code and provisioned with Ansible is really very simple. Indeed, MongoDB makes things much easier for us because it only takes a few lines of configuration to activate replication.\n\nThe whole logic of primary server election and re-definition is managed by MongoDB.\n\nTo go further with MongoDB replication, I invite you to browse the official MongoDB documentation which explains very well, with diagrams, operation and the various configuration parameters available to configure your replicas:[https://docs.mongodb.com/v3.0/core/replication-introduction/#replication-introduction](https://docs.mongodb.com/v3.0/core/replication-introduction/#replication-introduction).\n"}